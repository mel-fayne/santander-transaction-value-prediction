{"cells":[{"cell_type":"markdown","metadata":{"id":"FaDKI7E3LKl8"},"source":["## Importing libraries\n","_____"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15642,"status":"ok","timestamp":1674402361153,"user":{"displayName":"KABIRU SHARLEEN NJERI","userId":"04515185141378317434"},"user_tz":-180},"id":"tKKXquTlHwBC","outputId":"7568693d-668d-45ac-92d9-85d3b67b9fb6"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: xgboost in /usr/local/lib/python3.8/dist-packages (0.90)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from xgboost) (1.21.6)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (from xgboost) (1.7.3)\n"]}],"source":["import pandas as pd\n","import numpy as np\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","import scipy.stats as stats\n","%matplotlib inline\n","\n","import warnings\n","warnings.simplefilter(action='ignore', category=FutureWarning)\n","\n","# Loading Model libraries\n","import sys\n","!{sys.executable} -m pip install xgboost\n","\n","from sklearn.ensemble import VotingClassifier\n","from xgboost import XGBClassifier\n","from sklearn.ensemble import GradientBoostingClassifier\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.linear_model import LogisticRegression\n","from statsmodels.stats.outliers_influence import variance_inflation_factor\n","from lightgbm import LGBMClassifier\n","from scipy.special import erfc\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.metrics import f1_score,accuracy_score,classification_report,confusion_matrix , recall_score, precision_score\n","from sklearn.metrics import roc_curve, roc_auc_score, log_loss\n","\n","from keras.layers import Input, Dense\n","from keras.models import Model\n","\n","np.random.seed(2017)"]},{"cell_type":"markdown","metadata":{"id":"1mwZtHRhLoJR"},"source":["## Reading Files\n","_____"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":33507,"status":"ok","timestamp":1674402398750,"user":{"displayName":"KABIRU SHARLEEN NJERI","userId":"04515185141378317434"},"user_tz":-180},"id":"-HROcw1_U5qv","outputId":"79c93956-7625-4a91-d009-da1d5c3ee02d"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["# Mounting Google Drive\n","from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":317},"executionInfo":{"elapsed":5057,"status":"ok","timestamp":1674402444687,"user":{"displayName":"KABIRU SHARLEEN NJERI","userId":"04515185141378317434"},"user_tz":-180},"id":"hHdPBpgSLsDI","outputId":"de14786c-6bc4-4d26-ce06-e0268b927cfc"},"outputs":[{"name":"stdout","output_type":"stream","text":["The shape of the dataset is: (4459, 4993)\n"]},{"data":{"text/html":["\n","  <div id=\"df-dd01fffb-747c-44bd-98ab-adda622f6e8a\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>ID</th>\n","      <th>target</th>\n","      <th>48df886f9</th>\n","      <th>0deb4b6a8</th>\n","      <th>34b15f335</th>\n","      <th>a8cb14b00</th>\n","      <th>2f0771a37</th>\n","      <th>30347e683</th>\n","      <th>d08d1fbe3</th>\n","      <th>6ee66e115</th>\n","      <th>...</th>\n","      <th>3ecc09859</th>\n","      <th>9281abeea</th>\n","      <th>8675bec0b</th>\n","      <th>3a13ed79a</th>\n","      <th>f677d4d13</th>\n","      <th>71b203550</th>\n","      <th>137efaa80</th>\n","      <th>fb36b89d9</th>\n","      <th>7e293fbaf</th>\n","      <th>9fc776466</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>000d6aaf2</td>\n","      <td>38000000.0</td>\n","      <td>0.0</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>000fbd867</td>\n","      <td>600000.0</td>\n","      <td>0.0</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0027d6b71</td>\n","      <td>10000000.0</td>\n","      <td>0.0</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0028cbf45</td>\n","      <td>2000000.0</td>\n","      <td>0.0</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>002a68644</td>\n","      <td>14400000.0</td>\n","      <td>0.0</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 4993 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-dd01fffb-747c-44bd-98ab-adda622f6e8a')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-dd01fffb-747c-44bd-98ab-adda622f6e8a button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-dd01fffb-747c-44bd-98ab-adda622f6e8a');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["          ID      target  48df886f9  0deb4b6a8  34b15f335  a8cb14b00  \\\n","0  000d6aaf2  38000000.0        0.0          0        0.0          0   \n","1  000fbd867    600000.0        0.0          0        0.0          0   \n","2  0027d6b71  10000000.0        0.0          0        0.0          0   \n","3  0028cbf45   2000000.0        0.0          0        0.0          0   \n","4  002a68644  14400000.0        0.0          0        0.0          0   \n","\n","   2f0771a37  30347e683  d08d1fbe3  6ee66e115  ...  3ecc09859  9281abeea  \\\n","0          0          0          0          0  ...        0.0        0.0   \n","1          0          0          0          0  ...        0.0        0.0   \n","2          0          0          0          0  ...        0.0        0.0   \n","3          0          0          0          0  ...        0.0        0.0   \n","4          0          0          0          0  ...        0.0        0.0   \n","\n","   8675bec0b  3a13ed79a  f677d4d13  71b203550  137efaa80  fb36b89d9  \\\n","0        0.0          0          0          0          0          0   \n","1        0.0          0          0          0          0          0   \n","2        0.0          0          0          0          0          0   \n","3        0.0          0          0          0          0          0   \n","4        0.0          0          0          0          0          0   \n","\n","   7e293fbaf  9fc776466  \n","0          0          0  \n","1          0          0  \n","2          0          0  \n","3          0          0  \n","4          0          0  \n","\n","[5 rows x 4993 columns]"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["train_data = pd.read_csv(\"/content/drive/MyDrive/School/DataScience/santander-value-prediction-challenge/train.csv\")\n","# Preview the first five rows of the train dataset\n","print(f'The shape of the dataset is: {train_data.shape}')\n","train_data.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":317},"executionInfo":{"elapsed":47853,"status":"ok","timestamp":1674402504940,"user":{"displayName":"KABIRU SHARLEEN NJERI","userId":"04515185141378317434"},"user_tz":-180},"id":"5XKpPb_773X0","outputId":"225362e8-c8f2-41a7-881f-7fbe71e18603"},"outputs":[{"name":"stdout","output_type":"stream","text":["The shape of the dataset is: (49342, 4992)\n"]},{"data":{"text/html":["\n","  <div id=\"df-f2a05abe-e9e7-4c4d-b953-3ad69dd4c12b\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>ID</th>\n","      <th>48df886f9</th>\n","      <th>0deb4b6a8</th>\n","      <th>34b15f335</th>\n","      <th>a8cb14b00</th>\n","      <th>2f0771a37</th>\n","      <th>30347e683</th>\n","      <th>d08d1fbe3</th>\n","      <th>6ee66e115</th>\n","      <th>20aa07010</th>\n","      <th>...</th>\n","      <th>3ecc09859</th>\n","      <th>9281abeea</th>\n","      <th>8675bec0b</th>\n","      <th>3a13ed79a</th>\n","      <th>f677d4d13</th>\n","      <th>71b203550</th>\n","      <th>137efaa80</th>\n","      <th>fb36b89d9</th>\n","      <th>7e293fbaf</th>\n","      <th>9fc776466</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>000137c73</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>00021489f</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0004d7953</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>00056a333</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>00056d8eb</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 4992 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f2a05abe-e9e7-4c4d-b953-3ad69dd4c12b')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-f2a05abe-e9e7-4c4d-b953-3ad69dd4c12b button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-f2a05abe-e9e7-4c4d-b953-3ad69dd4c12b');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["          ID  48df886f9  0deb4b6a8  34b15f335  a8cb14b00  2f0771a37  \\\n","0  000137c73        0.0        0.0        0.0        0.0        0.0   \n","1  00021489f        0.0        0.0        0.0        0.0        0.0   \n","2  0004d7953        0.0        0.0        0.0        0.0        0.0   \n","3  00056a333        0.0        0.0        0.0        0.0        0.0   \n","4  00056d8eb        0.0        0.0        0.0        0.0        0.0   \n","\n","   30347e683  d08d1fbe3  6ee66e115  20aa07010  ...  3ecc09859  9281abeea  \\\n","0        0.0        0.0        0.0        0.0  ...        0.0        0.0   \n","1        0.0        0.0        0.0        0.0  ...        0.0        0.0   \n","2        0.0        0.0        0.0        0.0  ...        0.0        0.0   \n","3        0.0        0.0        0.0        0.0  ...        0.0        0.0   \n","4        0.0        0.0        0.0        0.0  ...        0.0        0.0   \n","\n","   8675bec0b  3a13ed79a  f677d4d13  71b203550  137efaa80  fb36b89d9  \\\n","0        0.0        0.0        0.0        0.0        0.0        0.0   \n","1        0.0        0.0        0.0        0.0        0.0        0.0   \n","2        0.0        0.0        0.0        0.0        0.0        0.0   \n","3        0.0        0.0        0.0        0.0        0.0        0.0   \n","4        0.0        0.0        0.0        0.0        0.0        0.0   \n","\n","   7e293fbaf  9fc776466  \n","0        0.0        0.0  \n","1        0.0        0.0  \n","2        0.0        0.0  \n","3        0.0        0.0  \n","4        0.0        0.0  \n","\n","[5 rows x 4992 columns]"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["test_data = pd.read_csv(\"/content/drive/MyDrive/School/DataScience/santander-value-prediction-challenge/test.csv\")\n","# Preview the first five rows of the test dataset\n","print(f'The shape of the dataset is: {test_data.shape}')\n","test_data.head()"]},{"cell_type":"markdown","metadata":{"id":"ldZwYz2oEr-N"},"source":["**Observations**: \n"," *   We are provided with an anonymized dataset containing numeric feature variables, the numeric target column, and a string ID column\n","\n","* The train data and test data  has 4993 and 4992  unique Columns \n","* the train data has 4459 rows \n","* the test data has 49342 rows \n","* In the Train data , the Number of columns is more than the number of train rows.\n","* in the Test data the Number of Rows  is almost 10 times the Number of Columns "]},{"cell_type":"markdown","metadata":{"id":"_thAiFPbbYQ5"},"source":["## DATA UNDERSTANDING "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8qGZgZlJcacp"},"outputs":[],"source":["# check datatypes\n","train_data.info()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YSSe_M69cbXI"},"outputs":[],"source":["test_data.info()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GHco3YyGcb-U"},"outputs":[],"source":["# describing numerical values in train data \n","train_data.describe().T"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"P8zTwW2LdM0u"},"outputs":[],"source":["# Categorical Values/Object Values in train data \n","train_data.describe(include=\"O\").T"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"go5bY1nPdR2x"},"outputs":[],"source":["# describing numerical values in test data \n","test_data.describe().T"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"c4IgV6B7dRmo"},"outputs":[],"source":["# Categorical Values/Object Values in test data \n","test_data.describe(include=\"O\").T"]},{"cell_type":"markdown","metadata":{"id":"ltN7XnRjdjY5"},"source":["### Checking for nulls and duplicates"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7sjAyQCCdo8B"},"outputs":[],"source":["#checking for missing value in train data \n","train_data.isnull().sum().sort_values(ascending=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GR43q8rqdozs"},"outputs":[],"source":["#checking for missing value in test \n","test_data.isnull().sum().sort_values(ascending=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aLpK4jHvdono"},"outputs":[],"source":["#duplicate train data rows  \n","train_data.duplicated().sum()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6lqJL3ooexpQ"},"outputs":[],"source":["#duplicate test data rows \n","test_data.duplicated().sum()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7Q27mU1O-HO7"},"outputs":[],"source":["#checking for duplicated column name since all column are anyonymous \n","# get the boolean array of duplicate column names\n","duplicate_col = train_data.columns.duplicated()\n","\n","# check if there are any duplicate column names\n","if any(duplicate_col):\n","    print(\"There are duplicate column names\")\n","else:\n","    print(\"All column names are unique\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4U20l5oCDhF6"},"outputs":[],"source":["# get the boolean array of duplicate column names\n","duplicate_col = test_data.columns.duplicated()\n","\n","# check if there are any duplicate column names\n","if any(duplicate_col):\n","    print(\"There are duplicate column names\")\n","else:\n","    print(\"All column names are unique\")"]},{"cell_type":"markdown","metadata":{"id":"bnS9gM52e6Z6"},"source":["**Observations**: \n","1. The train and test dataset is full of zeros \n","2. The train and test dataset has 0 missing value \n","3. The train and test dataset has 0 duplicate rows\n","4. All the column names are unique"]},{"cell_type":"markdown","metadata":{"id":"6BryEBt_cPFb"},"source":["## DATA PREPARATION"]},{"cell_type":"markdown","metadata":{"id":"wDjhLTqSl9YR"},"source":["## Reducing dimensionality using Autoencoder\n","_________"]},{"cell_type":"markdown","metadata":{"id":"yx5VwGo-FrqR"},"source":["Dimensionality reduction is the process of reducing the number of features or variables in a dataset while preserving as much of the important information as possible. This can be useful for visualizing high-dimensional data, reducing the computational cost of modeling, and avoiding overfitting. \n","\n","\n","\n","Autoencoder is an unsupervised neural network that learns to reconstruct the input data by compressing it into a lower-dimensional representation (encoding) and then decompressing it back to its original form (decoding). It can be used for dimensionality reduction by using the encoded representation as a new feature space.\n","\n","**Steps involved**: \n","* Prepare Data\n","* Design Auto Encoder\n","* Train Auto Encoder\n","* Use Encoder to obtain reduced dimensionality data for train and test sets\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XGVTH0fJQpAd"},"outputs":[],"source":["# lets first create a copy of the train and test data \n","train_df = train_data.copy()\n","test_df = test_data.copy()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2316,"status":"ok","timestamp":1674402519303,"user":{"displayName":"KABIRU SHARLEEN NJERI","userId":"04515185141378317434"},"user_tz":-180},"id":"hCWnuhsAFxUV","outputId":"824aeeac-532e-44e0-f211-18eb58b3c6db"},"outputs":[{"name":"stdout","output_type":"stream","text":["(4459, 4991)\n","(49342, 4991)\n"]}],"source":["# drop the target and id column from the train data and test data to protect them from encoding\n","train_df.drop(train_df[['ID', 'target']], axis=1, inplace=True)\n","test_df.drop(test_df[['ID']], axis=1, inplace= True)\n","print(train_df.shape)\n","print(test_df.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"A2Ahr0wCIFAh"},"outputs":[],"source":["# scale the train and test data for neural network  \n","# Create the scaler object\n","scaler = StandardScaler()\n","# Scale the train data data\n","train_scaled = scaler.fit_transform(train_df )\n","test_scaled = scaler.fit_transform(test_df )"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lFyZ0t9CJfLS"},"outputs":[],"source":["np.random.seed(2017)\n","X_train, X_test = train_test_split(train_scaled, train_size = 0.9, random_state = np.random.seed(2017))\n"]},{"cell_type":"markdown","metadata":{"id":"eS5CmdsLpmj6"},"source":["**Defining the input layer** \n","* We define different input layers for the train and test datasets \n","* This is because they have different number of columns which means they'll have different input dimensions\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pzzYbjPNS5zi"},"outputs":[],"source":["train_col_no = train_scaled.shape[1] #retrieve the no of col in train data we use the attribute shape to return the number of col\n","train_input_dim = Input(shape = (train_col_no, )) #create the input layer with the specified shape \n","\n","# Defining the encoder dimension and set to 200\n","encoding_dim = 200\n","\n","# Creating  Encoder Layers\n","encoded1 = Dense(3000, activation = 'relu')(train_input_dim)# we  create the first layer using the Dense function from Keras and specifies a hidden layer with 3000 units\n","encoded2 = Dense(2750, activation = 'relu')(encoded1)#Each subsequent layer is created by applying the previous layer to the Dense function, with a different number of units  \n","encoded3 = Dense(2500, activation = 'relu')(encoded2)\n","encoded4 = Dense(2250, activation = 'relu')(encoded3)\n","encoded5 = Dense(2000, activation = 'relu')(encoded4)\n","encoded6 = Dense(1750, activation = 'relu')(encoded5)\n","encoded7 = Dense(1500, activation = 'relu')(encoded6)\n","encoded8 = Dense(1250, activation = 'relu')(encoded7)\n","encoded9 = Dense(1000, activation = 'relu')(encoded8)\n","encoded10 = Dense(750, activation = 'relu')(encoded9)\n","encoded11 = Dense(500, activation = 'relu')(encoded10)\n","encoded12 = Dense(250, activation = 'relu')(encoded11)\n","encoded13 = Dense(encoding_dim, activation = 'relu')(encoded12) # the final layer has encoding_dim no of unit \n","\n","# Creating the Decoder Layers\n","decoded1 = Dense(250, activation = 'relu')(encoded13)\n","decoded2 = Dense(500, activation = 'relu')(decoded1)\n","decoded3 = Dense(750, activation = 'relu')(decoded2)\n","decoded4 = Dense(1000, activation = 'relu')(decoded3)\n","decoded5 = Dense(1250, activation = 'relu')(decoded4)\n","decoded6 = Dense(1500, activation = 'relu')(decoded5)\n","decoded7 = Dense(1750, activation = 'relu')(decoded6)\n","decoded8 = Dense(2000, activation = 'relu')(decoded7)\n","decoded9 = Dense(2250, activation = 'relu')(decoded8)\n","decoded10 = Dense(2500, activation = 'relu')(decoded9)\n","decoded11 = Dense(2750, activation = 'relu')(decoded10)\n","decoded12 = Dense(3000, activation = 'relu')(decoded11)\n","decoded13 = Dense(train_col_no, activation = 'sigmoid')(decoded12)\n","\n","# Creating the autoenconder\n","# The combined Encoder and Decoder layers input will be the input dim layer and output is the decode layer \n","train_autoencoder = Model(inputs = train_input_dim, outputs = decoded13)\n","\n","# Compiling the Model\n","train_autoencoder.compile(optimizer = 'adadelta', loss = 'binary_crossentropy')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":496,"status":"ok","timestamp":1674402541384,"user":{"displayName":"KABIRU SHARLEEN NJERI","userId":"04515185141378317434"},"user_tz":-180},"id":"uCP9JLXXTUaf","outputId":"d3c8d62b-3b77-491c-edff-0823a6c387fa"},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"model\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_1 (InputLayer)        [(None, 4991)]            0         \n","                                                                 \n"," dense (Dense)               (None, 3000)              14976000  \n","                                                                 \n"," dense_1 (Dense)             (None, 2750)              8252750   \n","                                                                 \n"," dense_2 (Dense)             (None, 2500)              6877500   \n","                                                                 \n"," dense_3 (Dense)             (None, 2250)              5627250   \n","                                                                 \n"," dense_4 (Dense)             (None, 2000)              4502000   \n","                                                                 \n"," dense_5 (Dense)             (None, 1750)              3501750   \n","                                                                 \n"," dense_6 (Dense)             (None, 1500)              2626500   \n","                                                                 \n"," dense_7 (Dense)             (None, 1250)              1876250   \n","                                                                 \n"," dense_8 (Dense)             (None, 1000)              1251000   \n","                                                                 \n"," dense_9 (Dense)             (None, 750)               750750    \n","                                                                 \n"," dense_10 (Dense)            (None, 500)               375500    \n","                                                                 \n"," dense_11 (Dense)            (None, 250)               125250    \n","                                                                 \n"," dense_12 (Dense)            (None, 200)               50200     \n","                                                                 \n"," dense_13 (Dense)            (None, 250)               50250     \n","                                                                 \n"," dense_14 (Dense)            (None, 500)               125500    \n","                                                                 \n"," dense_15 (Dense)            (None, 750)               375750    \n","                                                                 \n"," dense_16 (Dense)            (None, 1000)              751000    \n","                                                                 \n"," dense_17 (Dense)            (None, 1250)              1251250   \n","                                                                 \n"," dense_18 (Dense)            (None, 1500)              1876500   \n","                                                                 \n"," dense_19 (Dense)            (None, 1750)              2626750   \n","                                                                 \n"," dense_20 (Dense)            (None, 2000)              3502000   \n","                                                                 \n"," dense_21 (Dense)            (None, 2250)              4502250   \n","                                                                 \n"," dense_22 (Dense)            (None, 2500)              5627500   \n","                                                                 \n"," dense_23 (Dense)            (None, 2750)              6877750   \n","                                                                 \n"," dense_24 (Dense)            (None, 3000)              8253000   \n","                                                                 \n"," dense_25 (Dense)            (None, 4991)              14977991  \n","                                                                 \n","=================================================================\n","Total params: 101,590,191\n","Trainable params: 101,590,191\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}],"source":["train_autoencoder.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1204853,"status":"ok","timestamp":1674403752371,"user":{"displayName":"KABIRU SHARLEEN NJERI","userId":"04515185141378317434"},"user_tz":-180},"id":"_fxnTudBTfjS","outputId":"74749ea5-8776-48b4-9f1b-a2653ca75de2"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/10\n","126/126 [==============================] - 119s 923ms/step - loss: 0.6931 - val_loss: 0.6931\n","Epoch 2/10\n","126/126 [==============================] - 116s 922ms/step - loss: 0.6931 - val_loss: 0.6931\n","Epoch 3/10\n","126/126 [==============================] - 115s 917ms/step - loss: 0.6931 - val_loss: 0.6931\n","Epoch 4/10\n","126/126 [==============================] - 116s 917ms/step - loss: 0.6931 - val_loss: 0.6931\n","Epoch 5/10\n","126/126 [==============================] - 121s 960ms/step - loss: 0.6931 - val_loss: 0.6931\n","Epoch 6/10\n","126/126 [==============================] - 118s 935ms/step - loss: 0.6931 - val_loss: 0.6931\n","Epoch 7/10\n","126/126 [==============================] - 116s 921ms/step - loss: 0.6931 - val_loss: 0.6931\n","Epoch 8/10\n","126/126 [==============================] - 116s 921ms/step - loss: 0.6931 - val_loss: 0.6931\n","Epoch 9/10\n","126/126 [==============================] - 116s 922ms/step - loss: 0.6931 - val_loss: 0.6931\n","Epoch 10/10\n","126/126 [==============================] - 151s 1s/step - loss: 0.6931 - val_loss: 0.6931\n"]},{"data":{"text/plain":["<keras.callbacks.History at 0x7f893d6a5460>"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["# Once the autoencoder is compiled, we train it using the training dataset.\n","train_autoencoder.fit(X_train, X_train, epochs = 10, batch_size = 32, shuffle = False, validation_data = (X_test, X_test))"]},{"cell_type":"markdown","metadata":{"id":"avvn8FrdHrn8"},"source":["Using the encoder to reduce dimensionality:\n","* Once the autoencoder is trained, you can use the encoder part of the autoencoder to reduce the dimensionality of the dataset. By calling the predict() function on the encoder, you can transform the input data to a lower-dimensional representation."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3qfOYtAoAxSP"},"outputs":[],"source":["# We use the autoencoder to reduce the dimension of the train dataset\n","train_encoder = Model(inputs = train_input_dim, outputs = encoded13)\n","train_encoded_input = Input(shape = (encoding_dim, ))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GQJGEt1RBDKy"},"outputs":[],"source":["# Predict the new train and test using the autoencoder \n","new_train = pd.DataFrame(train_encoder.predict(train_scaled))\n","new_train = new_train.add_prefix('feature_')\n"]},{"cell_type":"markdown","metadata":{"id":"StGUNMHsvD0i"},"source":["**We repeat the same process for the test dataset**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Y6Tk5uKN-tQk"},"outputs":[],"source":["np.random.seed(2017)\n","Y_train, Y_test = train_test_split(test_scaled, train_size = 0.9, random_state = np.random.seed(2017))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"--U5tOsKpZDA"},"outputs":[],"source":["test_col_no = test_scaled.shape[1]\n","test_input_dim = Input(shape = (test_col_no, ))\n","\n","encoding_dim = 200\n","\n","encoded1 = Dense(3000, activation = 'relu')(test_input_dim)\n","encoded2 = Dense(2750, activation = 'relu')(encoded1)\n","encoded3 = Dense(2500, activation = 'relu')(encoded2)\n","encoded4 = Dense(2250, activation = 'relu')(encoded3)\n","encoded5 = Dense(2000, activation = 'relu')(encoded4)\n","encoded6 = Dense(1750, activation = 'relu')(encoded5)\n","encoded7 = Dense(1500, activation = 'relu')(encoded6)\n","encoded8 = Dense(1250, activation = 'relu')(encoded7)\n","encoded9 = Dense(1000, activation = 'relu')(encoded8)\n","encoded10 = Dense(750, activation = 'relu')(encoded9)\n","encoded11 = Dense(500, activation = 'relu')(encoded10)\n","encoded12 = Dense(250, activation = 'relu')(encoded11)\n","encoded13 = Dense(encoding_dim, activation = 'relu')(encoded12)\n","\n","decoded1 = Dense(250, activation = 'relu')(encoded13)\n","decoded2 = Dense(500, activation = 'relu')(decoded1)\n","decoded3 = Dense(750, activation = 'relu')(decoded2)\n","decoded4 = Dense(1000, activation = 'relu')(decoded3)\n","decoded5 = Dense(1250, activation = 'relu')(decoded4)\n","decoded6 = Dense(1500, activation = 'relu')(decoded5)\n","decoded7 = Dense(1750, activation = 'relu')(decoded6)\n","decoded8 = Dense(2000, activation = 'relu')(decoded7)\n","decoded9 = Dense(2250, activation = 'relu')(decoded8)\n","decoded10 = Dense(2500, activation = 'relu')(decoded9)\n","decoded11 = Dense(2750, activation = 'relu')(decoded10)\n","decoded12 = Dense(3000, activation = 'relu')(decoded11)\n","decoded13 = Dense(test_col_no, activation = 'sigmoid')(decoded12)\n","\n","test_autoencoder = Model(inputs = test_input_dim, outputs = decoded13)\n","\n","test_autoencoder.compile(optimizer = 'adadelta', loss = 'binary_crossentropy')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zZY0JnWLtoCq"},"outputs":[],"source":["test_autoencoder.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"t8K26XAutxlf"},"outputs":[],"source":["test_autoencoder.fit(Y_train, Y_train, epochs = 10, batch_size = 32, shuffle = False, validation_data = (Y_test, Y_test))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YmmhpAP7t-7n"},"outputs":[],"source":["test_encoder = Model(inputs = test_input_dim, outputs = encoded13)\n","test_encoded_input = Input(shape = (encoding_dim, ))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"i9qBpEEyOwIn"},"outputs":[],"source":["new_test = pd.DataFrame(test_encoder.predict(test_scaled))\n","new_test = new_test.add_prefix('feature_')"]},{"cell_type":"markdown","metadata":{"id":"5nzY8wYQuY9Y"},"source":["**Adding back the columns dropped before encoding**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CjTaPjhVBVty"},"outputs":[],"source":["# We then add back the target and the Id code we droped earlier \n","train_df_1 = pd.concat([train_data[['ID', 'target']], new_train], axis=1)\n","print(train_df_1.shape)\n","train_df_1.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZPlTBAtNBfmN"},"outputs":[],"source":["# Viewing the shape of the new test data \n","test_df_1 = pd.concat([test_data[['ID']], new_test], axis=1)\n","print(test_df_1.shape)\n","test_df_1.head()\n"]},{"cell_type":"markdown","metadata":{"id":"2kntZZEVvcWb"},"source":["## Exporting the reduced Datasets"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"P9dhpNkTvf1D"},"outputs":[],"source":["# We then extract the reduced datasets for further pre processing\n","train_df_1.to_csv(r'reduced_train.csv', index=False)\n","test_df_1.to_csv(r'reduced_test.csv', index=False)"]}],"metadata":{"colab":{"provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"base","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]"},"vscode":{"interpreter":{"hash":"36be0d2bf4bb6007abf66e79295eb6ba1209eff99d4539ea8facd3206f5f7add"}}},"nbformat":4,"nbformat_minor":0}
