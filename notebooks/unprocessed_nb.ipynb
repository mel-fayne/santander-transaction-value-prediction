{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSC 418 Group D Data Science Project\n",
    "\n",
    "Category : **Major**\n",
    "Group Members\n",
    " \n",
    "1. P15/5620/2019 : Njagi Baraka Fadhili\n",
    "2. P15/1636/2019 : Kabiru Sharleen Njeri\n",
    "3. P15/1635/2019 : Obora Melanie Fayne\n",
    "4. P15/137631/2019 : Ali Amina Abdi\n",
    "5. P15/130607/2018 : Munyao Mary June"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing libraries\n",
    "_____"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score,accuracy_score,classification_report,confusion_matrix ,recall_score, precision_score, roc_curve, roc_auc_score"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading Files\n",
    "\n",
    "____"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"../data/train.csv\", header=0)\n",
    "# Preview the first five rows of the train dataset\n",
    "print(f'The shape of the dataset is: {train_data.shape}')\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv(\"../data/test.csv\", header=0)\n",
    "# Preview the first five rows of the test dataset\n",
    "print(f'The shape of the dataset is: {test_data.shape}')\n",
    "test_data.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Immediate Observations**\n",
    "\n",
    "* We are provided with an anonymized dataset containing numeric feature variables, the numeric target column, and a string ID column\n",
    "* The train data and test data  has 4992 unique Columns \n",
    "* the train data has 4459 rows \n",
    "* the test data has 49342 rows \n",
    "* In the Train data , the Number of columns is more than the number of train rows.\n",
    "* Test data is almost 10 times as that of train set."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting the train dataset for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select main columns to be used in training\n",
    "main_cols = train_data.columns.difference(['ID_code', 'target'])\n",
    "X = train_data[main_cols]\n",
    "y = train_data.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.3, random_state=42)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline Model using Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lr = LogisticRegression()\n",
    "model_lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction\n",
    "y_pred_lr = model_lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy is : ', accuracy_score(y_test, y_pred_lr))\n",
    "print(f'F1 score on the X_test is: {f1_score(y_test, y_pred_lr)}')\n",
    "print(' recall:', recall_score(y_test, y_pred_lr))\n",
    "print(' precision:',precision_score(y_test, y_pred_lr))\n",
    "print('Area under the ROC curve:' , roc_auc_score(y_test, y_pred_lr))\n",
    "confusion = confusion_matrix(y_test, y_pred_lr)\n",
    "print(f'Confusion Matrix on the X_test is:\\n {confusion}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting The Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make prediction on the test set\n",
    "test_df = test_data[main_cols]\n",
    "predictions = model_lr.predict(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sample_sub = pd.read_csv('/data/sample_submission.csv')\n",
    "# Create a submission file\n",
    "sub_file = sample_sub.copy()\n",
    "sub_file.predictions = predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the distribution of our predictions\n",
    "sns.countplot(sub_file.predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_file.to_csv('Unprocessed_Lr_Submission.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "36be0d2bf4bb6007abf66e79295eb6ba1209eff99d4539ea8facd3206f5f7add"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
