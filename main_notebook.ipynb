{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSC 418 Group D Data Science Project\n",
    "\n",
    "Category : **Major**\n",
    "Group Members\n",
    " \n",
    "1. P15/5620/2019 : Njagi Baraka Fadhili\n",
    "2. P15/1636/2019 : Kabiru Sharleen Njeri\n",
    "3. P15/1635/2019 : Obora Melanie Fayne\n",
    "4. P15/137631/2019 : Ali Amina Abdi\n",
    "5. P15/130607/2018 : Munyao Mary June"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing libraries\n",
    "_____"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: lightgbm in c:\\users\\mel_fayne\\anaconda3\\lib\\site-packages (3.3.4)\n",
      "Requirement already satisfied: numpy in c:\\users\\mel_fayne\\anaconda3\\lib\\site-packages (from lightgbm) (1.21.5)\n",
      "Requirement already satisfied: scikit-learn!=0.22.0 in c:\\users\\mel_fayne\\anaconda3\\lib\\site-packages (from lightgbm) (1.0.2)\n",
      "Requirement already satisfied: wheel in c:\\users\\mel_fayne\\anaconda3\\lib\\site-packages (from lightgbm) (0.37.1)\n",
      "Requirement already satisfied: scipy in c:\\users\\mel_fayne\\anaconda3\\lib\\site-packages (from lightgbm) (1.9.1)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\mel_fayne\\anaconda3\\lib\\site-packages (from scikit-learn!=0.22.0->lightgbm) (1.1.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\mel_fayne\\anaconda3\\lib\\site-packages (from scikit-learn!=0.22.0->lightgbm) (2.2.0)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "%matplotlib inline\n",
    "\n",
    "import sys\n",
    "!{sys.executable} -m pip install xgboost\n",
    "import sys\n",
    "!{sys.executable} -m pip install lightgbm;\n",
    "\n",
    "from tqdm import tqdm\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from lightgbm import LGBMClassifier\n",
    "from scipy.special import erfc\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score,accuracy_score,classification_report,confusion_matrix ,recall_score, precision_score\n",
    "from sklearn.metrics import roc_curve, roc_auc_score"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading Files\n",
    "\n",
    "____"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the dataset is: (4459, 4993)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>target</th>\n",
       "      <th>48df886f9</th>\n",
       "      <th>0deb4b6a8</th>\n",
       "      <th>34b15f335</th>\n",
       "      <th>a8cb14b00</th>\n",
       "      <th>2f0771a37</th>\n",
       "      <th>30347e683</th>\n",
       "      <th>d08d1fbe3</th>\n",
       "      <th>6ee66e115</th>\n",
       "      <th>...</th>\n",
       "      <th>3ecc09859</th>\n",
       "      <th>9281abeea</th>\n",
       "      <th>8675bec0b</th>\n",
       "      <th>3a13ed79a</th>\n",
       "      <th>f677d4d13</th>\n",
       "      <th>71b203550</th>\n",
       "      <th>137efaa80</th>\n",
       "      <th>fb36b89d9</th>\n",
       "      <th>7e293fbaf</th>\n",
       "      <th>9fc776466</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000d6aaf2</td>\n",
       "      <td>38000000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000fbd867</td>\n",
       "      <td>600000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0027d6b71</td>\n",
       "      <td>10000000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0028cbf45</td>\n",
       "      <td>2000000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>002a68644</td>\n",
       "      <td>14400000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 4993 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          ID      target  48df886f9  0deb4b6a8  34b15f335  a8cb14b00  \\\n",
       "0  000d6aaf2  38000000.0        0.0          0        0.0          0   \n",
       "1  000fbd867    600000.0        0.0          0        0.0          0   \n",
       "2  0027d6b71  10000000.0        0.0          0        0.0          0   \n",
       "3  0028cbf45   2000000.0        0.0          0        0.0          0   \n",
       "4  002a68644  14400000.0        0.0          0        0.0          0   \n",
       "\n",
       "   2f0771a37  30347e683  d08d1fbe3  6ee66e115  ...  3ecc09859  9281abeea  \\\n",
       "0          0          0          0          0  ...        0.0        0.0   \n",
       "1          0          0          0          0  ...        0.0        0.0   \n",
       "2          0          0          0          0  ...        0.0        0.0   \n",
       "3          0          0          0          0  ...        0.0        0.0   \n",
       "4          0          0          0          0  ...        0.0        0.0   \n",
       "\n",
       "   8675bec0b  3a13ed79a  f677d4d13  71b203550  137efaa80  fb36b89d9  \\\n",
       "0        0.0          0          0          0          0          0   \n",
       "1        0.0          0          0          0          0          0   \n",
       "2        0.0          0          0          0          0          0   \n",
       "3        0.0          0          0          0          0          0   \n",
       "4        0.0          0          0          0          0          0   \n",
       "\n",
       "   7e293fbaf  9fc776466  \n",
       "0          0          0  \n",
       "1          0          0  \n",
       "2          0          0  \n",
       "3          0          0  \n",
       "4          0          0  \n",
       "\n",
       "[5 rows x 4993 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = pd.read_csv(\"./data/train.csv\")\n",
    "# Preview the first five rows of the train dataset\n",
    "print(f'The shape of the dataset is: {train_data.shape}')\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the dataset is: (49342, 4992)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>48df886f9</th>\n",
       "      <th>0deb4b6a8</th>\n",
       "      <th>34b15f335</th>\n",
       "      <th>a8cb14b00</th>\n",
       "      <th>2f0771a37</th>\n",
       "      <th>30347e683</th>\n",
       "      <th>d08d1fbe3</th>\n",
       "      <th>6ee66e115</th>\n",
       "      <th>20aa07010</th>\n",
       "      <th>...</th>\n",
       "      <th>3ecc09859</th>\n",
       "      <th>9281abeea</th>\n",
       "      <th>8675bec0b</th>\n",
       "      <th>3a13ed79a</th>\n",
       "      <th>f677d4d13</th>\n",
       "      <th>71b203550</th>\n",
       "      <th>137efaa80</th>\n",
       "      <th>fb36b89d9</th>\n",
       "      <th>7e293fbaf</th>\n",
       "      <th>9fc776466</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000137c73</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00021489f</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0004d7953</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00056a333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00056d8eb</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 4992 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          ID  48df886f9  0deb4b6a8  34b15f335  a8cb14b00  2f0771a37  \\\n",
       "0  000137c73        0.0        0.0        0.0        0.0        0.0   \n",
       "1  00021489f        0.0        0.0        0.0        0.0        0.0   \n",
       "2  0004d7953        0.0        0.0        0.0        0.0        0.0   \n",
       "3  00056a333        0.0        0.0        0.0        0.0        0.0   \n",
       "4  00056d8eb        0.0        0.0        0.0        0.0        0.0   \n",
       "\n",
       "   30347e683  d08d1fbe3  6ee66e115  20aa07010  ...  3ecc09859  9281abeea  \\\n",
       "0        0.0        0.0        0.0        0.0  ...        0.0        0.0   \n",
       "1        0.0        0.0        0.0        0.0  ...        0.0        0.0   \n",
       "2        0.0        0.0        0.0        0.0  ...        0.0        0.0   \n",
       "3        0.0        0.0        0.0        0.0  ...        0.0        0.0   \n",
       "4        0.0        0.0        0.0        0.0  ...        0.0        0.0   \n",
       "\n",
       "   8675bec0b  3a13ed79a  f677d4d13  71b203550  137efaa80  fb36b89d9  \\\n",
       "0        0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "1        0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "2        0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "3        0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "4        0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "\n",
       "   7e293fbaf  9fc776466  \n",
       "0        0.0        0.0  \n",
       "1        0.0        0.0  \n",
       "2        0.0        0.0  \n",
       "3        0.0        0.0  \n",
       "4        0.0        0.0  \n",
       "\n",
       "[5 rows x 4992 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = pd.read_csv(\"./data/test.csv\")\n",
    "# Preview the first five rows of the test dataset\n",
    "print(f'The shape of the dataset is: {test_data.shape}')\n",
    "test_data.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Understanding and Preparation\n",
    "_____"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Things to check for**:\n",
    "\n",
    "1. Check for fake data in the train and test datasets: *Criteria to use: It is fake if it has no unique values*\n",
    "2. Check for null and duplicate values \n",
    "3. Check for Outliers\n",
    "4. Check for Feature Distribution\n",
    "5. Check for Feature Importance: using corellation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking for Data Uniqueness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's first create a copy of the train and test data \n",
    "train_df = train_data.copy()\n",
    "test_df = test_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we then drop the target and ID code columns for the train and test \n",
    "train_df.drop(train_df[['ID', 'target']], axis=1, inplace=True)\n",
    "test_df.drop(test_df[['ID']], axis=1, inplace= True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking the Train Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig = [f'var_{i}' for i in range(200)]\n",
    "has_one = [f'var_{i}_has_one' for i in range(200)]\n",
    "has_zero = [f'var_{i}_has_zero' for i in range(200)]\n",
    "not_u = [f'var_{i}_not_unique' for i in range(200)]\n",
    "\n",
    "for f in tqdm(orig):\n",
    "    unique_v = train_df[f].value_counts()\n",
    "    unique_v = unique_v.index[unique_v == 1]\n",
    "    train_df[f + '_u'] = train_df[f].isin(unique_v)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell above defines four lists of strings, orig, has_one, has_zero, and not_u, which contain the names of 200 variables in the format 'var_i' where i is a number from 0 to 199.\n",
    "\n",
    "Next, the code enters a loop that iterates over the orig list. For each iteration of the loop, the code calculates the number of unique values in the corresponding column of the train dataframe. It then selects the values that occur only once, and creates a new column in the train dataFrame that indicates whether each value in the original column is in the list of unique values.\n",
    "\n",
    "The tqdm function is used to wrap the loop and display a progress bar that shows the progress of the loop. This can be useful when the loop is running over a large number of iterations and you want to have some sense of how long it will take to complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['has_unique'] = train_df[[f + '_u' for f in orig]].any(axis=1)\n",
    "print(train_df['has_unique'].sum())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell above creates a new column called 'has_unique' in the train dataframe. The new column is a boolean column that indicates whether any of the original 4992 variables in train dataset have any unique values.\n",
    "\n",
    "The new column is created by selecting a sub-DataFrame from train data that contains all of the columns with names ending in '_u'. This sub-DataFrame is created using a list comprehension that generates a list of column names by adding '_u' to each element of the orig list. The any function is then used to check whether any of the values in the sub-DataFrame are True. The axis=1 parameter specifies that the operation should be performed column-wise, rather than row-wise.\n",
    "\n",
    "Finally, the cell prints the sum of the 'has_unique' column, which is the number of rows in test_data where at least one of the original 4992 variables has a unique value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_train = train_df.loc[train_df['has_unique'], orig]\n",
    "new_train = pd.concat([train_data[['ID', 'target']], real_train], axis=1)\n",
    "print(new_train.shape)\n",
    "new_train.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking the Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig = [f'var_{i}' for i in range(200)]\n",
    "has_one = [f'var_{i}_has_one' for i in range(200)]\n",
    "has_zero = [f'var_{i}_has_zero' for i in range(200)]\n",
    "not_u = [f'var_{i}_not_unique' for i in range(200)]\n",
    "\n",
    "for f in tqdm(orig):\n",
    "    unique_v = test_df[f].value_counts()\n",
    "    unique_v = unique_v.index[unique_v == 1]\n",
    "    test_df[f + '_u'] = test_df[f].isin(unique_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['has_unique'] = test_df[[f + '_u' for f in orig]].any(axis=1)\n",
    "print(test_df['has_unique'].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_test = test_df.loc[test_df['has_unique'], orig]\n",
    "real_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets create the new test data \n",
    "new_test = pd.concat([test_data['ID'], real_test], axis=1)\n",
    "new_testdata = new_test.dropna()\n",
    "print(new_testdata.shape)\n",
    "new_testdata.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking for Data Types, Duplicates and Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_train.info() # check datatypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_testdata.info() # check datatypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_train.describe() # check datatypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# describing numerical values\n",
    "new_testdata.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorical Values/Object Values\n",
    "new_train.describe(include=\"O\").T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorical Values/Object Values\n",
    "new_testdata.describe(include=\"O\").T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#missing value \n",
    "new_train.isnull().sum().sort_values(ascending=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_testdata.isnull().sum().sort_values(ascending=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#duplicate data \n",
    "new_train.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#duplicate data \n",
    "new_test.duplicated().sum()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations**\n",
    "\n",
    "*   We are provided with an anonymized dataset containing numeric feature variables, the numeric target column, and a string ID column\n",
    "*   The dataset has 202 unique Columns and 300,000 rows\n",
    "*   The dataset has 0 missing value \n",
    "*   The dataset has 0 duplicate rows "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking for Outliers"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using Chauvenet's criterion to check for outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chauvenet(array):\n",
    "    mean = array.mean()           # Mean of incoming array\n",
    "    stdv = array.std()            # Standard deviation\n",
    "    N = len(array)                # Lenght of incoming array\n",
    "    criterion = 1.0/(2*N)         # Chauvenet's criterion\n",
    "    d = abs(array-mean)/stdv      # Distance of a value to mean in stdv's\n",
    "    prob = erfc(d)                # Area normal dist.    \n",
    "    return prob < criterion       # Use boolean array outside this function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_features=new_train.columns[2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outliers = dict() \n",
    "for col in [col for col in numerical_features]:\n",
    "    outliers[col] = new_train[chauvenet(new_train[col].values)].shape[0]\n",
    "outliers = pd.Series(outliers)\n",
    "\n",
    "outliers.sort_values().plot(figsize=(14, 40), kind='barh').set_xlabel('Number of outliers');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Total number of outliers in the train data: {} ({:.2f}%)'.format(sum(outliers.values), (sum(outliers.values) / new_train.shape[0]) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_features=new_testdata.columns[2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outliers = dict() \n",
    "for col in [col for col in numerical_features]:\n",
    "    outliers[col] = new_testdata[chauvenet(new_testdata[col].values)].shape[0]\n",
    "outliers = pd.Series(outliers)\n",
    "\n",
    "outliers.sort_values().plot(figsize=(14, 40), kind='barh').set_xlabel('Number of outliers');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Total number of outliers in the test dataset: {} ({:.2f}%)'.format(sum(outliers.values), (sum(outliers.values) / new_testdata.shape[0]) * 100))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using Z-score to check for outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------- Using z-score\n",
    "#train data\n",
    "data=new_train[new_train.columns.difference(['target','ID'])]\n",
    "stats.zscore(data)\n",
    "stats.zscore(data, axis=1)\n",
    "data.apply(stats.zscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------- Using z-score\n",
    "\n",
    "data=new_testdata[new_testdata.columns.difference(['ID'])]\n",
    "stats.zscore(data)\n",
    "stats.zscore(data, axis=1)\n",
    "data.apply(stats.zscore)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using IQR to remove outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=new_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking for outlier using IQR \n",
    "for i in new_train[new_train.columns.difference(['target', 'ID','has_unique'], sort=False)].columns:\n",
    "  q25 = data[i].quantile(0.25)\n",
    "  q75 = data[i].quantile(0.75)\n",
    "  # Calculating the IQR\n",
    "  IQR = q75 - q25\n",
    "  # Specifying the lower and upper limit\n",
    "  lower_limit = q25 - 1.5 * IQR\n",
    "  upper_limit = q75 + 1.5 * IQR\n",
    "  # Removing outliers\n",
    "  dataset = data.loc[(data[i] > lower_limit) & (data[i] < upper_limit)]\n",
    "  sns.boxplot(data = data, y = i)\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=new_testdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking for outlier using IQR in test data \n",
    "for i in new_testdata[new_testdata.columns.difference(['ID_code'], sort=False)].columns:\n",
    "  q25 = data[i].quantile(0.25)\n",
    "  q75 = data[i].quantile(0.75)\n",
    "  # Calculating the IQR\n",
    "  IQR = q75 - q25\n",
    "  # Specifying the lower and upper limit\n",
    "  lower_limit = q25 - 1.5 * IQR\n",
    "  upper_limit = q75 + 1.5 * IQR\n",
    "  # Removing outliers\n",
    "  dataset = data.loc[(data[i] > lower_limit) & (data[i] < upper_limit)]\n",
    "  sns.boxplot(data = data, y = i)\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dataset Description After removing the outliers\n",
    "new_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_testdata.describe()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking for Feature Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Distributions of first 100 columns of the dataset')\n",
    "\n",
    "plt.figure(figsize=(40, 200))\n",
    "for i, col in enumerate(list(new_train.columns)[2:102]):\n",
    "    plt.subplot(25,4, i + 1) #The first argument is the number of plots in each row and the second the number of plots per column\n",
    "    plt.hist(dataset[col])\n",
    "    plt.title(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Distributions of the last 100 columns the dataset')\n",
    "\n",
    "plt.figure(figsize=(40, 200))\n",
    "for i, col in enumerate(list(new_train.columns)[102:]):\n",
    "    plt.subplot(25, 4, i + 1)\n",
    "    plt.hist(dataset[col])\n",
    "    plt.title(col)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observation**: All the variables are normalized distributed but not scaled "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Performing Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the columns to scale\n",
    "features=new_train.columns[2:]\n",
    "# Create the scaler object\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the scaler to the data\n",
    "scaler.fit(new_train[features])\n",
    "\n",
    "# Scale the data\n",
    "new_train[features] = scaler.fit_transform(new_train[features])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking for Feature Importance using Corelation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_train.corr(method=\"pearson\").style.background_gradient(cmap=\"rocket_r\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**General Interprataion of Pearson Co-relation**\n",
    "1. **Perfect**: Near Â± 1.\n",
    "2. **High**: Â± 0.50 to Â± 1\n",
    "3. **Moderate**: Â± 0.30 to Â± 0.49\n",
    "4. **Low** degree: Below + 0.2\n",
    "5. **None** : 0\n",
    "\n",
    "**Observation**: \n",
    "* The correlation coefficient has values between -1 to 1\n",
    "* The correlations between the features is very low being mostly between +0.008 and -0.008. There are NO strong correlations at all between the different feature"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Checking for the target distribution aganist the variables "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of columns per target class\n",
    "print(\"Distribution of columns per target class\")\n",
    "sns.set_style('darkgrid')\n",
    "plt.figure(figsize=(40,200));\n",
    "for i,col in enumerate(list(new_train.columns)[2:]):\n",
    "    plt.subplot(50,4,i+1 ,);\n",
    "    sns.distplot(new_train[new_train['target']==0][col],hist=False,label='0',color='green');\n",
    "    sns.distplot(new_train[new_train['target']==1][col],hist=False,label='1',color='red');"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observation**: The target variable is normally distributed across all the variables "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Checking The Target Column distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# target value count \n",
    "new_train[\"target\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# target value count plot \n",
    "sns.countplot(new_train['target'], palette='Set2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target Variable Analysis\n",
    "plt.figure(figsize=(12,8))\n",
    "sns.distplot(dataset[\"target\"].values, bins=50, kde=True)\n",
    "plt.xlabel('Target --> ', fontsize=12)\n",
    "plt.title(\"target distribution\", fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observation**: The target variable is imbalanced and more biased towards 0"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting the train dataset for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select main columns to be used in training\n",
    "main_cols = new_train.columns.difference(['ID_code', 'target'])\n",
    "X = new_train[main_cols]\n",
    "y = new_train.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.3, random_state=42)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Balancing the target Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking Distribution of Target Variable\n",
    "y_train.value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Synthetic Minority Over-sampling Technique (SMOTE) is a popular over-sampling method. it generates synthetic samples of the minority class, instead of just duplicating existing ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smote = SMOTE()\n",
    "# Fit and transform the data\n",
    "X_train, y_train = smote.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking Distribution of Target Variable after normalisation\n",
    "np.unique(y_train, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#target value count plot after normalising\n",
    "sns.countplot(y_train, palette='Set2')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Different Classifier Algorithms"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lr = LogisticRegression()\n",
    "model_lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction\n",
    "y_pred_lr = model_lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy is : ', accuracy_score(y_test, y_pred_lr))\n",
    "print(f'F1 score on the X_test is: {f1_score(y_test, y_pred_lr)}')\n",
    "print(' recall:', recall_score(y_test, y_pred_lr))\n",
    "print(' precision:',precision_score(y_test, y_pred_lr))\n",
    "print('Area under the ROC curve:' , roc_auc_score(y_test, y_pred_lr))\n",
    "confusion = confusion_matrix(y_test, y_pred_lr)\n",
    "print(f'Confusion Matrix on the X_test is:\\n {confusion}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**F1 Score Board**\n",
    "\n",
    "1.   Logistic Regression "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. LGBM Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lgbm = LGBMClassifier()\n",
    "model_lgbm.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_lgbm = model_lgbm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy is : ', accuracy_score(y_test, y_pred_lgbm))\n",
    "print(f'F1 score on the X_test is: {f1_score(y_test, y_pred_lgbm)}')\n",
    "print(' recall:', recall_score(y_test, y_pred_lgbm))\n",
    "print(' precision:',precision_score(y_test, y_pred_lgbm))\n",
    "print('Area under the ROC curve:' , roc_auc_score(y_test, y_pred_lgbm))\n",
    "confusion = confusion_matrix(y_test, y_pred_lgbm)\n",
    "print(f'Confusion Matrix on the X_test is:\\n {confusion}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**F1 Scrore Board**\n",
    "\n",
    "1.   LGBMClassifier : \n",
    "2.   Logistic Regression : \n",
    "\n",
    "Improved by ****"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_rf = RandomForestClassifier(criterion='entropy')   \n",
    "model_rf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_rf = model_rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check accuracy, F1 score and Confusion Matrix\n",
    "\n",
    "print('Accuracy is : ', accuracy_score(y_test, y_pred_rf))\n",
    "print(f'F1 score on the X_test is: {f1_score(y_test, y_pred_rf)}')\n",
    "print(' recall:', recall_score(y_test, y_pred_rf))\n",
    "print(' precision:',precision_score(y_test, y_pred_rf))\n",
    "print('Area under the ROC curve:' , roc_auc_score(y_test, y_pred_rf))\n",
    "confusion = confusion_matrix(y_test, y_pred_rf)\n",
    "print(f'Confusion Matrix on the X_test is:\\n {confusion}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**F1 Scrore Board**\n",
    "\n",
    "1.   RandomForestClassifier :\n",
    "2.   LGBMClassifier :\n",
    "3.   Logistic Regression :\n",
    "\n",
    "Improved by ****"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Gradient Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "model_gb = GradientBoostingClassifier(\n",
    "    n_estimators = 400,\n",
    "    learning_rate = 1.0,\n",
    "    min_samples_leaf = 10,\n",
    "    subsample = 1.0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_gb.fit(X_train, y_train)\n",
    "\n",
    "y_pred_gb = model_gb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check accuracy, F1 score and Confusion Matrix\n",
    "\n",
    "print('Accuracy is : ', accuracy_score(y_test, y_pred_gb))\n",
    "print(f'F1 score on the X_test is: {f1_score(y_test, y_pred_gb)}')\n",
    "print(' recall:', recall_score(y_test, y_pred_gb))\n",
    "print(' precision:',precision_score(y_test, y_pred_gb))\n",
    "print('Area under the ROC curve:' , roc_auc_score(y_test, y_pred_gb))\n",
    "confusion = confusion_matrix(y_test, y_pred_gb)\n",
    "print(f'Confusion Matrix on the X_test is:\\n {confusion}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**F1 Scrore Board**\n",
    "\n",
    "1.   Gradient Classifier :\n",
    "2.   RandomForestClassifier :\n",
    "3.   LGBMClassifier :\n",
    "4.   Logistic Regression :\n",
    "\n",
    "Improved by ****"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. XGBoost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "model_xg = XGBClassifier()\n",
    "\n",
    "model_xg.fit(X_train, y_train)\n",
    "\n",
    "y_pred_xg = model_xg.predict(X_test)\n",
    "\n",
    "print('Accuracy is : ', accuracy_score(y_test, y_pred_xg))\n",
    "print(f'F1 score on the X_test is: {f1_score(y_test, y_pred_xg)}')\n",
    "print(' recall:', recall_score(y_test, y_pred_xg))\n",
    "print(' precision:',precision_score(y_test, y_pred_xg))\n",
    "print('Area under the ROC curve:' , roc_auc_score(y_test, y_pred_xg))\n",
    "confusion = confusion_matrix(y_test, y_pred_xg)\n",
    "print(f'Confusion Matrix on the X_test is:\\n {confusion}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**F1 Scrore Board**\n",
    "\n",
    "1.   Gradient Classifier :\n",
    "2.   RandomForestClassifier :\n",
    "3.   LGBMClassifier :\n",
    "4.   Logistic Regression :\n",
    "5.   XGBoost Classifier :\n",
    "\n",
    "Improved by ****"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Ensemble Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing voting classifier\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "# Making the final model using voting classifier\n",
    "final_model = VotingClassifier(\n",
    "\testimators=[('lr', model_lr), ('lgbm', model_lgbm)], voting='soft')\n",
    "\n",
    "# training all the model on the train dataset\n",
    "final_model.fit(X_train, y_train)\n",
    "\n",
    "# predicting the output on the test dataset\n",
    "pred_final = final_model.predict(X_test)\n",
    "\n",
    "# printing log loss between actual and predicted value\n",
    "print(log_loss(y_test, pred_final))\n",
    "\n",
    "print('Accuracy is : ', accuracy_score(y_test, pred_final))\n",
    "print(f'F1 score on the X_test is: {f1_score(y_test, pred_final)}')\n",
    "print(' recall:', recall_score(y_test, pred_final))\n",
    "print(' precision:',precision_score(y_test, pred_final))\n",
    "print('Area under the ROC curve:' , roc_auc_score(y_test, pred_final))\n",
    "confusion = confusion_matrix(y_test, pred_final)\n",
    "print(f'Confusion Matrix on the X_test is:\\n {confusion}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**F1 Scrore Board**\n",
    "\n",
    "1.   Gradient Classifier :\n",
    "2.   RandomForestClassifier :\n",
    "3.   LGBMClassifier :\n",
    "4.   Logistic Regression :\n",
    "5.   XGBoost Classifier :\n",
    "6.   Ensemble :\n",
    "\n",
    "Improved by ****"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting The Test Dataset with our Star Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make prediction on the test set\n",
    "test_df = test_df[main_cols]\n",
    "predictions = model_lgbm.predict(test_df)\n",
    "\n",
    "# Create a submission file\n",
    "sub_file = sample_sub.copy()\n",
    "sub_file.predictions = predictions\n",
    "\n",
    "# Check the distribution of our predictions\n",
    "sns.countplot(sub_file.predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "36be0d2bf4bb6007abf66e79295eb6ba1209eff99d4539ea8facd3206f5f7add"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
